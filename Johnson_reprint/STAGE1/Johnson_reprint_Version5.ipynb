{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOHNSON REPRINT VERSION 5 ###\n",
    "#\n",
    "### PROCESS SUMMARY ###\n",
    "# for each alphabet section, loops through each line collecting:\n",
    "## counts for each author (including multiple authors in a line) (10 authors)\n",
    "## string of the full line each time an author name is detected, paired in a list with respective author name (10 authors)\n",
    "# when detects 'alphasectend':\n",
    "## writes author counts to a text file (10 authors)\n",
    "## writers string-author string pairs to a CSV file (10 authors)\n",
    "## moves on to the next alphabet section\n",
    "#\n",
    "## NOTES ON TEXT ##\n",
    "# lines 1-7348 (slice [0:7347]) are intro text (line 7348 is 'alphasectend' string for intro)\n",
    "# dictionary content begins on line 7349 (slice [7348:])\n",
    "# improved cleanline function                                 #from Johnson_reprint_cleaning_V2\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating clean_line function...\")\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    cleanline = cleanline.replace(\"°\", \"o\")\n",
    "    cleanline = cleanline.replace(\"º\", \"o\")\n",
    "    cleanline = cleanline.replace(\"×\", \"x\")\n",
    "    cleanline = cleanline.replace(\"à\", \"a\")\n",
    "    cleanline = cleanline.replace(\"á\", 'a')\n",
    "    cleanline = cleanline.replace('â', 'a')\n",
    "    cleanline = cleanline.replace('ä', 'a')\n",
    "    cleanline = cleanline.replace('ă', 'a')\n",
    "    cleanline = cleanline.replace('ã', 'a')\n",
    "    cleanline = cleanline.replace('å', 'a')\n",
    "    cleanline = cleanline.replace('ā', 'a')\n",
    "    cleanline = cleanline.replace('ą', 'a')\n",
    "    cleanline = cleanline.replace('ć', 'c')\n",
    "    cleanline = cleanline.replace('č', 'c')\n",
    "    cleanline = cleanline.replace('ç', 'c')\n",
    "    cleanline = cleanline.replace('è', 'e')\n",
    "    cleanline = cleanline.replace('é', 'e')\n",
    "    cleanline = cleanline.replace('ë', 'e')\n",
    "    cleanline = cleanline.replace('ē', 'e')\n",
    "    cleanline = cleanline.replace('ę', 'e')\n",
    "    cleanline = cleanline.replace('ê', 'e')\n",
    "    cleanline = cleanline.replace('ğ', 'g')\n",
    "    cleanline = cleanline.replace('í', 'i')\n",
    "    cleanline = cleanline.replace('ì', 'i')\n",
    "    cleanline = cleanline.replace('ń', 'n')\n",
    "    cleanline = cleanline.replace('ñ', 'n')\n",
    "    cleanline = cleanline.replace('ň', 'n')\n",
    "    cleanline = cleanline.replace('ó', 'o')\n",
    "    cleanline = cleanline.replace('ö', 'o')\n",
    "    cleanline = cleanline.replace('ð', 'o')\n",
    "    cleanline = cleanline.replace('ø', 'o')\n",
    "    cleanline = cleanline.replace('ò', 'o')\n",
    "    cleanline = cleanline.replace('ř', 'r')\n",
    "    cleanline = cleanline.replace('š', 's')\n",
    "    cleanline = cleanline.replace(\"ſ\", \"s\")\n",
    "    cleanline = cleanline.replace('ś', 's')\n",
    "    cleanline = cleanline.replace('ş', 's')\n",
    "    cleanline = cleanline.replace('ţ', 't')\n",
    "    cleanline = cleanline.replace('ü', 'u')\n",
    "    cleanline = cleanline.replace('ú', 'u')\n",
    "    cleanline = cleanline.replace('ū', 'u')\n",
    "    cleanline = cleanline.replace('ź', 'z')\n",
    "    cleanline = cleanline.replace('ż', 'z')\n",
    "    cleanline = cleanline.replace('ž', 'z')\n",
    "    return cleanline\n",
    "#\n",
    "print(\"Success: created clean_line function!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Johnson_reprint volume                                 #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "print(\"Opening dictionary text...\")\n",
    "infile = open('uc1.31175025730543.txt','r', encoding='utf-8')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "print(\"Success: opened, read, and closed text!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into lines                                 #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "print(\"Splitting into lines...\")\n",
    "lines_list = text.split('\\n')\n",
    "print(\"Success: split into lines!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean lines and add cleaned lines to a list        #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "print(\"Cleaning lines...\")\n",
    "cleaned_lines_list = []\n",
    "for line in lines_list:\n",
    "    cleaned_line = \" \" + clean_line(line) + \" \"    #space buffer is for regex\n",
    "    cleaned_lines_list.append(cleaned_line)\n",
    "print(\"Success: cleaned lines!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of two-item lists (for writing to a CSV):\n",
    "# key = alphabet section     #value = empty list for author-string list pairs (list of two-item lists)\n",
    "print(\"Creating dictionary of lists...\")\n",
    "alpha_dictionary = {\"A\":[], \"B\":[], \"C\":[], \"D\":[], \"E\":[], \"F\":[], \"G\":[], \"H\":[], \"I\":[], \"K\":[], \"L\":[], \"M\":[], \"N\":[], \"O\":[], \"P\":[], \"Q\":[], \"R\":[], \"S\":[], \"T\":[], \"U\":[], \"W\":[], \"X\":[], \"Y\":[], \"Z\":[]}\n",
    "print(\"Success: created dictionary of lists!\")\n",
    "#\n",
    "import csv\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Johnson_reprint_counts_V5.txt...\")\n",
    "outfile_total_count = open(\"Johnson_reprint_counts_V5.txt\", 'w', encoding=\"UTF-8\")\n",
    "print(\"Success: created Johnson_reprint_counts_V5.txt!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define starting alpha_sect (\"A\")\n",
    "print(\"Defining alpha sect...\")\n",
    "alpha_sect = 65\n",
    "print(\"Success: defined alpha sect!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regex pattern functions\n",
    "print(\"Compiling regex patterns...\")\n",
    "import re\n",
    "shak = re.compile('[\\s]sha[okfli][^l][^n]')# Shakespeare\n",
    "spens = re.compile('[\\s]sp[eo\\s][nos]s[oe\\s]') # Spenser\n",
    "sidn = re.compile('[\\s]sid[\\.nrh]') # Sidney\n",
    "lestr = re.compile('[^a-z^\\s]e[si\\/][tir\\/][r\\.]') # L'Estrange\n",
    "dryd1 = re.compile('ry[^i^\\s^n]') # Dryden #1\n",
    "dryd2 = re.compile('dry[\\s][dl][eo][hnr]') # Dryden #2\n",
    "locke = re.compile('[ldzij\\s\\.1]oc[klł][eo][^a-z]') # Locke\n",
    "prior = re.compile('[\\s]pri[zoec]r[^a-z]') # Prior\n",
    "swift = re.compile('[^a-z]sw[li][sft][tf][^a-z^\\-^;]') # Swift\n",
    "addis1 = re.compile('[\\sadl][da]ison[^a-z]') # Addison 1\n",
    "addis2 = re.compile('4d[ido][nis]') # Addison 2\n",
    "pope = re.compile('[^a-z]p[^i]p[ec][^a-z]') # Pope\n",
    "#\n",
    "print(\"Success: compiled regex patterns!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions that add author-citation pairs to CSV\n",
    "print(\"Defining author-citation functions...\")\n",
    "#\n",
    "# Shakespeare\n",
    "def finding_shakespeare(x_line):\n",
    "    shak = re.compile('[\\s]sha[okfli][^l][^n]')\n",
    "    shak_appears = shak.findall(x_line)\n",
    "    if shak_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Shakespeare\"])\n",
    "# Spenser\n",
    "def finding_spenser(x_line):\n",
    "    spens = re.compile('[\\s]sp[eo\\s][nos]s[oe\\s]')\n",
    "    spens_appears = spens.findall(x_line)\n",
    "    if spens_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Spenser\"])\n",
    "# Sidney\n",
    "def finding_sidney(x_line):\n",
    "    sidn = re.compile('[\\s]sid[\\.nrh]')\n",
    "    sidn_appears = sidn.findall(x_line)\n",
    "    if sidn_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Sidney\"])\n",
    "# L'Estrange\n",
    "def finding_lestrange(x_line):\n",
    "    lestr = re.compile('[^a-z^\\s]e[si\\/][tir\\/][r\\.]')\n",
    "    lestr_appears = lestr.findall(x_line)\n",
    "    if lestr_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"L\\'Estrange\"])\n",
    "# Dryden1\n",
    "def finding_dryden1(x_line):\n",
    "    dryd1 = re.compile('ry[^i^\\s^n]')\n",
    "    dryd1_appears = dryd1.findall(x_line)\n",
    "    if dryd1_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Dryden\"])\n",
    "# Dryden2\n",
    "def finding_dryden2(x_line):\n",
    "    dryd2 = re.compile('dry[\\s][dl][eo][hnr]')\n",
    "    dryd2_appears = dryd2.findall(x_line)\n",
    "    if dryd2_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Dryden\"])\n",
    "# Locke\n",
    "def finding_locke(x_line):\n",
    "    locke = re.compile('[ldzij\\s\\.1]oc[klł][eo][^a-z]')\n",
    "    locke_appears = locke.findall(x_line)\n",
    "    if locke_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Locke\"])\n",
    "# Prior\n",
    "def finding_prior(x_line):\n",
    "    prior = re.compile('[\\s]pri[zoec]r[^a-z]')\n",
    "    prior_appears = prior.findall(x_line)\n",
    "    if prior_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Prior\"])\n",
    "# Swift\n",
    "def finding_swift(x_line):\n",
    "    swift = re.compile('[^a-z]sw[li][sft][tf][^a-z^\\-^;]')\n",
    "    swift_appears = swift.findall(x_line)\n",
    "    if swift_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Swift\"])\n",
    "# Addison1\n",
    "def finding_addison1(x_line):\n",
    "    addis1 = re.compile('[\\sadl][da]ison[^a-z]')\n",
    "    addis1_appears = addis1.findall(x_line)\n",
    "    if addis1_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Addison\"])\n",
    "# Addison2\n",
    "def finding_addison2(x_line):\n",
    "    addis2 = re.compile('4d[ido][nis]')\n",
    "    addis2_appears = addis2.findall(x_line)\n",
    "    if addis2_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Addison\"])\n",
    "# Pope\n",
    "def finding_pope(x_line):\n",
    "    pope = re.compile('[^a-z]p[^i]p[ec][^a-z]')\n",
    "    pope_appears = pope.findall(x_line)\n",
    "    if pope_appears:\n",
    "        alpha_dictionary[chr(alpha_sect)].append([line, \"Pope\"])\n",
    "#\n",
    "print(\"Success: defined author-citation functions!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define author count variables\n",
    "print(\"Defining author count variables...\")\n",
    "shakespeares = 0\n",
    "spensers = 0\n",
    "sidneys = 0\n",
    "lestranges = 0\n",
    "drydens = 0\n",
    "lockes = 0\n",
    "priors = 0\n",
    "swifts = 0\n",
    "addisons = 0\n",
    "popes = 0\n",
    "print(\"Success: defined author count variables!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Counting authors and collecting data...\")\n",
    "for line in cleaned_lines_list[7348:]:\n",
    "    if 'alphasectend' in line:\n",
    "        # write dictionary contents to CSV                   ## CSV COUNT ##\n",
    "        with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts_V5.csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "            filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "            for pair in alpha_dictionary[chr(alpha_sect)]:\n",
    "                citation_string = pair[0]\n",
    "                label = pair[1]\n",
    "                row = [label, citation_string]\n",
    "                filewriter.writerow(row)\n",
    "        print(\"Data for alphabet section \" + str(chr(alpha_sect)) + \" successfully written to CSV file.\")\n",
    "\n",
    "        # define count result statements\n",
    "        section_header = (\"ALPHABET SECTION: \" + str(chr(alpha_sect)))\n",
    "        shak_counts_statement = (\"Shakespeare citations = \" + str(shakespeares))\n",
    "        spens_counts_statement = (\"Spenser citations = \" + str(spensers))\n",
    "        sidn_counts_statement = (\"Sidney citations = \" + str(sidneys))\n",
    "        lestr_counts_statement = (\"L\\'Estrange citations \" + str(lestranges))\n",
    "        dryd_counts_statement = (\"Dryden citations = \" + str(drydens))\n",
    "        locke_counts_statement = (\"Locke citations = \" + str(lockes))\n",
    "        prior_counts_statement = (\"Prior citations = \" + str(priors))\n",
    "        swift_counts_statement = (\"Swift citations = \" + str(swifts))\n",
    "        addis_counts_statement = (\"Addison citations = \" + str(addisons))\n",
    "        pope_counts_statement = (\"Pope citations = \" + str(popes))\n",
    "        section_border = (\"- - - - - - - - - - - - -\")\n",
    "        # print count results to text file\n",
    "        print(section_header, file=outfile_total_count)\n",
    "        print(shak_counts_statement, file=outfile_total_count)\n",
    "        print(spens_counts_statement, file=outfile_total_count)\n",
    "        print(sidn_counts_statement, file=outfile_total_count)\n",
    "        print(lestr_counts_statement, file=outfile_total_count)\n",
    "        print(dryd_counts_statement, file=outfile_total_count)\n",
    "        print(locke_counts_statement, file=outfile_total_count)\n",
    "        print(prior_counts_statement, file=outfile_total_count)\n",
    "        print(swift_counts_statement, file=outfile_total_count)\n",
    "        print(addis_counts_statement, file=outfile_total_count)\n",
    "        print(pope_counts_statement, file=outfile_total_count)\n",
    "        print(section_border, file=outfile_total_count)\n",
    "        print(\"Data for alphabet section \" + str(chr(alpha_sect)) + \" successfully written to text file.\")\n",
    "        # redefine alpha section\n",
    "        if alpha_sect == 73 or alpha_sect == 85:\n",
    "            alpha_sect = alpha_sect +2\n",
    "        else:\n",
    "            alpha_sect = alpha_sect + 1\n",
    "        # reset citations counts\n",
    "        shakespeares = 0\n",
    "        spensers = 0\n",
    "        sidneys = 0\n",
    "        lestranges = 0\n",
    "        drydens = 0\n",
    "        lockes = 0\n",
    "        priors = 0\n",
    "        swifts = 0\n",
    "        addisons = 0\n",
    "        popes = 0\n",
    "#\n",
    "    else:\n",
    "        # counting occurrences of author citations        \n",
    "        shakespeares = len(shak.findall(line)) + shakespeares\n",
    "        spensers = len(spens.findall(line)) + spensers\n",
    "        sidneys = len(sidn.findall(line)) + sidneys\n",
    "        lestranges = len(lestr.findall(line)) + lestranges\n",
    "        drydens = len(dryd1.findall(line)) + drydens\n",
    "        drydens = len(dryd2.findall(line)) + drydens\n",
    "        lockes = len(locke.findall(line)) + lockes\n",
    "        priors = len(prior.findall(line)) + priors\n",
    "        swifts = (len(swift.findall(line))) + swifts\n",
    "        addisons = (len(addis1.findall(line))) + addisons\n",
    "        addisons = (len(addis2.findall(line))) + addisons\n",
    "        popes = (len(pope.findall(line))) + popes\n",
    "        \n",
    "        # adding author-citation pairs to dictionary for printing to CSV\n",
    "        finding_shakespeare(line)\n",
    "        finding_spenser(line)\n",
    "        finding_sidney(line)\n",
    "        finding_lestrange(line)\n",
    "        finding_dryden1(line)\n",
    "        finding_dryden2(line)\n",
    "        finding_locke(line)\n",
    "        finding_prior(line)\n",
    "        finding_swift(line)\n",
    "        finding_addison1(line)\n",
    "        finding_addison2(line)\n",
    "        finding_pope(line)\n",
    "#\n",
    "print(\"Success: data collected!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Closing files..\")\n",
    "outfile_total_count.close()\n",
    "outfile_csv.close()\n",
    "print(\"Success: files closed!\")\n",
    "#\n",
    "print(\"Congrats! The program didn't fail! Check your folder to see your results!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
