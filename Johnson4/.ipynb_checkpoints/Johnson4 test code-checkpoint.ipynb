{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'johnson_volume1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9b2b5821fe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#open full text of dictionary                                   ## LISTS OF LINES AND WORDS ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'johnson_volume1.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'johnson_volume1.txt'"
     ]
    }
   ],
   "source": [
    "### ORIGINAL CODE WORKFLOW ####\n",
    "\n",
    "creates a dictionary where the key is a letter of the alphabet and the value is an empty dictionary for word counts\n",
    "creates a dictionary where the key is a letter of the alphabet and the value is the page count (starts at 0)\n",
    "creates an outfile containing the total counts, volume1_counts.txt\n",
    "\n",
    "opens volume I of the dictionary\n",
    "splits into a list of lines\n",
    "cleans each line in the list of lines (replaces special characters, removes punctuation)\n",
    "\n",
    "sets the current alphabet section to 'A'\n",
    "\n",
    "for each line, converts all words to lowercase and splits into individual words\n",
    "loops through words and adds to 'alpha_dictionary_*' dictionary, where the key is the current letter and the value is an empty dictionary for word counts\n",
    "while looping, keeps track of the page count (string flag = 'classpagenum')\n",
    "when the program detects that the alphabet section has ended (string flag = 'alphasectionend'), does the following\n",
    "# 1) creates a CSV file for the contents of 'alpha_dictionary_*'\n",
    "# 2) writes the contents of 'alpha_dictionary_*' to the CSV file\n",
    "# 3) evaluates the CSV file to find how many times 'shakes' appears\n",
    "# 4) adds together the shakespeare counts\n",
    "# 5) prints the results to the counts_statement.txt file\n",
    "# 6) redefines the alphabet section\n",
    "# 7) the next line is added to the newest alphabet section\n",
    "\n",
    "loop continues until no more lines are left\n",
    "\n",
    "\n",
    "### ORIGINAL CODE FOLLOWS ###\n",
    "\n",
    "print(\"Executing...\")\n",
    "\n",
    "import string\n",
    "\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    for punc in string.punctuation:\n",
    "         cleanline = cleanline.replace(punc, \"\")\n",
    "    cleanline = cleanline.replace('xc2xb', \"o\")\n",
    "    cleanline = cleanline.replace(\"xc2xba\", \"o\")\n",
    "    cleanline = cleanline.replace(\"xc3x97\", \"x\")\n",
    "    cleanline = cleanline.replace(\"xc3xa\", \"a\")\n",
    "    cleanline = cleanline.replace(\"xc3xa1\", 'a')\n",
    "    cleanline = cleanline.replace('xc3xa2', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa4', 'a')\n",
    "    cleanline = cleanline.replace('xc4x83', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa3', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa5', 'a')\n",
    "    cleanline = cleanline.replace('xc4x81', 'a')\n",
    "    cleanline = cleanline.replace('xc4x85', 'a')\n",
    "    cleanline = cleanline.replace('xc4x87', 'c')\n",
    "    cleanline = cleanline.replace('xc4x8d', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa7', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa8', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa9', 'e')\n",
    "    cleanline = cleanline.replace('xc3xab', 'e')\n",
    "    cleanline = cleanline.replace('xc4x93', 'e')\n",
    "    cleanline = cleanline.replace('xc4x99', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa', 'e')\n",
    "    cleanline = cleanline.replace('xc4x9f', 'g')\n",
    "    cleanline = cleanline.replace('xc3xad', 'i')\n",
    "    cleanline = cleanline.replace('xc3xac', 'i')\n",
    "    cleanline = cleanline.replace('xc5x84', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb1', 'n')\n",
    "    cleanline = cleanline.replace('xc5x88', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb3', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb6', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb8', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb2', 'o')\n",
    "    cleanline = cleanline.replace('xc5x99', 'r')\n",
    "    cleanline = cleanline.replace('xc5xa1', 's')\n",
    "    cleanline = cleanline.replace('xc5xbf', 's')\n",
    "    cleanline = cleanline.replace('xc5x9b', 's')\n",
    "    cleanline = cleanline.replace('xc5x9f', 's')\n",
    "    cleanline = cleanline.replace('xc5xa3', 't')\n",
    "    cleanline = cleanline.replace('xc3xbc', 'u')\n",
    "    cleanline = cleanline.replace('xc3xba', 'u')\n",
    "    cleanline = cleanline.replace('xc5xab', 'u')\n",
    "    cleanline = cleanline.replace('xc5xba', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbc', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbe', 'z')\n",
    "    cleanline = cleanline.replace('xc3x86', 'Æ')\n",
    "    return cleanline\n",
    "\n",
    "# dictionary of dictionaries:\n",
    "# key = alphabet section     #value = empty dictionary for word counts\n",
    "alpha_dictionary = {\"A\":{}, \"B\":{}, \"C\":{}, \"D\":{}, \"E\":{}, \"F\":{}, \"G\":{}, \"H\":{}, \"I\":{}, \"K\":{}}\n",
    "\n",
    "#dictionary of page numbers:\n",
    "pages = 0\n",
    "#key = alphabet section      #value = empty 'pages' variable\n",
    "page_counter = {\"A\": pages, \"B\": pages, \"C\": pages, \"D\": pages, \"E\": pages, \"F\": pages, \"G\": pages, \"H\": pages, \"I\": pages, \"K\": pages}\n",
    "\n",
    "import csv\n",
    "\n",
    "#define total counts text file outfile\n",
    "outfile_total_count = open(\"volume1_counts.txt\", 'w', encoding=\"UTF-8\")\n",
    "\n",
    "#open full text of dictionary                                   ## LISTS OF LINES AND WORDS ##\n",
    "infile = open('johnson_volume1.txt','rb')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "\n",
    "# split into lines\n",
    "lines_list = text.split('\\\\n')\n",
    "# print(\"success: split into lines\")\n",
    "\n",
    "# clean lines\n",
    "for line in lines_list:\n",
    "     clean = clean_line(line)\n",
    "#     clean_words = clean.split()\n",
    "# print(\"success clean words\")\n",
    "\n",
    "#define current alphabet letter section\n",
    "alpha_sect = 65\n",
    "\n",
    "#for loop over words\n",
    "\n",
    "for line in lines_list:\n",
    "    line = line.lower()\n",
    "    clean_words = clean_line(line).split()\n",
    "    for word in clean_words:\n",
    "        if word == 'alphasectionend':\n",
    "            #write dictionary contents to CSV                   ## CSV COUNT ##\n",
    "            with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "                filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "                filewriter.writerow(['word', 'count'])\n",
    "                for pair in alpha_dictionary[chr(alpha_sect)].items():\n",
    "                    label = pair[0]\n",
    "                    count = pair[1]\n",
    "                    row = [label, count]\n",
    "                    filewriter.writerow(row)\n",
    "\n",
    "        #evaluate CSV file to find shakespeare counts           ## SHAKESPEARE COUNT ##\n",
    "            with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'r', encoding=\"UTF-8\") as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                total_count = 0\n",
    "                other_count = 0\n",
    "                misc_list = []\n",
    "                for row in csv_reader:\n",
    "                    if \"shakes\" in row[0]:\n",
    "                        total_count = total_count + int(row[1])\n",
    "                    elif \"count\" in row[1]:\n",
    "                        misc_list.append(row[1])\n",
    "                    else:\n",
    "                        other_count = other_count + int(row[1])\n",
    "\n",
    "            #print count results to text file\n",
    "            counts_statement = (\"There are \" + str(page_counter[chr(alpha_sect)]) + \" pages and \" + str(total_count) + \" Shakespeare citations in the \" + str(chr(alpha_sect)) + \" section.\")\n",
    "            # print(counts_statement)\n",
    "            print(counts_statement, file=outfile_total_count)\n",
    "\n",
    "            #redefine alpha_sect\n",
    "            if alpha_sect == 73:\n",
    "                alpha_sect = alpha_sect + 2\n",
    "            else:\n",
    "                alpha_sect = alpha_sect + 1\n",
    "\n",
    "        #adding to page count\n",
    "        elif word == 'classpagenum':\n",
    "            page_counter[chr(alpha_sect)] = page_counter[chr(alpha_sect)] + 1\n",
    "\n",
    "        #adding words and counts to dictionary\n",
    "        else:                                                   ## DICTIONARY COUNT ##\n",
    "            if word not in alpha_dictionary[chr(alpha_sect)]:\n",
    "                alpha_dictionary[chr(alpha_sect)][word] = 1\n",
    "                # print(alpha_dictionary[chr(alpha_sect)])\n",
    "            else:\n",
    "                alpha_dictionary[chr(alpha_sect)][word] += 1\n",
    "\n",
    "outfile_csv.close()\n",
    "csv_file.close()\n",
    "outfile_total_count.close()\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Johnson4_v1 notes:\n",
    "\n",
    "## page cutoff flag = [div class=\"page\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important stuff\n",
    "\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex template\n",
    "import re\n",
    "\n",
    "shak = re.compile('shak[^i]')      #shakespeare pattern\n",
    "shakespeares = 0\n",
    "\n",
    "milton = re.compile('mil.')         #milton pattern\n",
    "miltons = 0\n",
    "\n",
    "locke = re.compile('loc.')        #locke pattern\n",
    "lockes = 0\n",
    "\n",
    "dryden = re.compile('dry[^i]')      #dryden pattern\n",
    "drydens = 0\n",
    "\n",
    "#total_lines = 0\n",
    "\n",
    "for line in lines_list:\n",
    "    shakespeares = len(shak.findall(line)) + shakespeares\n",
    "    miltons = len(re.findall(milton, line)) + miltons\n",
    "    lockes = len(re.findall(locke, line)) + lockes\n",
    "    drydens = len(re.findall(dryden, line)) + drydens\n",
    "#     if line == '':                            #keeps track of number of lines with content; not necessary to record\n",
    "#         total_lines = total_lines + 0\n",
    "#     else:\n",
    "#         total_lines = total_lines + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### alphabet sections for volume I ######\n",
    "\n",
    "#dictionary content starts on page 69, line 7341\n",
    "\n",
    "#A = pg 69\n",
    "#B = 206\n",
    "#C = 324\n",
    "#D = 545\n",
    "#E = 681\n",
    "#F = 772\n",
    "#G = 895\n",
    "#H = 973\n",
    "#I/J = 1053\n",
    "#K = 1162\n",
    "\n",
    "#to read only dictionary content (no intro text), slice \"cleaned_lines_list[7340:]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improved cleanline function                                 #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "import string\n",
    "\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    cleanline = cleanline.replace(\"°\", \"o\")\n",
    "    cleanline = cleanline.replace(\"º\", \"o\")\n",
    "    cleanline = cleanline.replace(\"×\", \"x\")\n",
    "    cleanline = cleanline.replace(\"à\", \"a\")\n",
    "    cleanline = cleanline.replace(\"á\", 'a')\n",
    "    cleanline = cleanline.replace('â', 'a')\n",
    "    cleanline = cleanline.replace('ä', 'a')\n",
    "    cleanline = cleanline.replace('ă', 'a')\n",
    "    cleanline = cleanline.replace('ã', 'a')\n",
    "    cleanline = cleanline.replace('å', 'a')\n",
    "    cleanline = cleanline.replace('ā', 'a')\n",
    "    cleanline = cleanline.replace('ą', 'a')\n",
    "    cleanline = cleanline.replace('ć', 'c')\n",
    "    cleanline = cleanline.replace('č', 'c')\n",
    "    cleanline = cleanline.replace('ç', 'c')\n",
    "    cleanline = cleanline.replace('è', 'e')\n",
    "    cleanline = cleanline.replace('é', 'e')\n",
    "    cleanline = cleanline.replace('ë', 'e')\n",
    "    cleanline = cleanline.replace('ē', 'e')\n",
    "    cleanline = cleanline.replace('ę', 'e')\n",
    "    cleanline = cleanline.replace('ê', 'e')\n",
    "    cleanline = cleanline.replace('ğ', 'g')\n",
    "    cleanline = cleanline.replace('í', 'i')\n",
    "    cleanline = cleanline.replace('ì', 'i')\n",
    "    cleanline = cleanline.replace('ń', 'n')\n",
    "    cleanline = cleanline.replace('ñ', 'n')\n",
    "    cleanline = cleanline.replace('ň', 'n')\n",
    "    cleanline = cleanline.replace('ó', 'o')\n",
    "    cleanline = cleanline.replace('ö', 'o')\n",
    "    cleanline = cleanline.replace('ð', 'o')\n",
    "    cleanline = cleanline.replace('ø', 'o')\n",
    "    cleanline = cleanline.replace('ò', 'o')\n",
    "    cleanline = cleanline.replace('ř', 'r')\n",
    "    cleanline = cleanline.replace('š', 's')\n",
    "    cleanline = cleanline.replace(\"ſ\", \"s\")\n",
    "    cleanline = cleanline.replace('ś', 's')\n",
    "    cleanline = cleanline.replace('ş', 's')\n",
    "    cleanline = cleanline.replace('ţ', 't')\n",
    "    cleanline = cleanline.replace('ü', 'u')\n",
    "    cleanline = cleanline.replace('ú', 'u')\n",
    "    cleanline = cleanline.replace('ū', 'u')\n",
    "    cleanline = cleanline.replace('ź', 'z')\n",
    "    cleanline = cleanline.replace('ż', 'z')\n",
    "    cleanline = cleanline.replace('ž', 'z')\n",
    "    return cleanline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: split into lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#open volume 1 of Johnson4                                 #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "infile = open('Johnson4_v1.txt','r', encoding='utf-8')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "\n",
    "# split into lines                                 #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "lines_list = text.split('\\n')\n",
    "print(\"success: split into lines\")\n",
    "\n",
    "#clean lines and add cleaned lines to a list        #from Johnson4_v1_split_alphasectend-retain-punct\n",
    "\n",
    "cleaned_lines_list = []\n",
    "for line in lines_list:\n",
    "    cleaned_line = clean_line(line)\n",
    "    cleaned_lines_list.append(cleaned_line)\n",
    "\n",
    "print(len(cleaned_lines_list))\n",
    "print(cleaned_lines_list[7340:])\n",
    "#final product: cleaned_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of dictionaries:\n",
    "# key = alphabet section     #value = empty dictionary for author-string pairs\n",
    "alpha_dictionary = {\"A\":{}, \"B\":{}, \"C\":{}, \"D\":{}, \"E\":{}, \"F\":{}, \"G\":{}, \"H\":{}, \"I\":{}, \"K\":{}}\n",
    "\n",
    "#dictionary of page numbers:\n",
    "pages = 0\n",
    "#key = alphabet section      #value = empty 'pages' variable\n",
    "page_counter = {\"A\": pages, \"B\": pages, \"C\": pages, \"D\": pages, \"E\": pages, \"F\": pages, \"G\": pages, \"H\": pages, \"I\": pages, \"K\": pages}\n",
    "\n",
    "import csv\n",
    "\n",
    "#define text outfile that will contain author citation counts\n",
    "outfile_total_count = open(\"volume1_counts.txt\", 'w', encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define current alphabet letter section\n",
    "alpha_sect = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define regex patterns\n",
    "\n",
    "import re\n",
    "\n",
    "shak = re.compile('shak[^i]')      #shakespeare pattern\n",
    "shakespeares = 0\n",
    "\n",
    "milton = re.compile('mil.')         #milton pattern\n",
    "miltons = 0\n",
    "\n",
    "locke = re.compile('loc.')        #locke pattern\n",
    "lockes = 0\n",
    "\n",
    "dryden = re.compile('dry[^i]')      #dryden pattern\n",
    "drydens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "#for loop over words\n",
    "\n",
    "for line in cleaned_lines_list[7340:]:\n",
    "#    print(line)\n",
    "    if 'alphasectend' in line:\n",
    "#         with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "#             filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "#             for pair in alpha_dictionary[chr(alpha_sect)].items():\n",
    "#                 label = pair[1]\n",
    "#                 citation_string = pair[0]\n",
    "#                 row = [label, citation_string]\n",
    "#                 filewriter.writerow(row)\n",
    "\n",
    "#         #evaluate CSV file to find shakespeare counts           ## SHAKESPEARE COUNT ##\n",
    "#         with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'r', encoding=\"UTF-8\") as csv_file:\n",
    "#             csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#             total_count = 0\n",
    "#             other_count = 0\n",
    "#             misc_list = []\n",
    "#             for row in csv_reader:\n",
    "#                 if \"shakes\" in row[0]:\n",
    "#                     total_count = total_count + int(row[1])\n",
    "#                 elif \"count\" in row[1]:\n",
    "#                     misc_list.append(row[1])\n",
    "#                 else:\n",
    "#                     other_count = other_count + int(row[1])\n",
    "\n",
    "        #print count results to text file\n",
    "        section_header = (\"ALPHABET SECTION: \" + str(chr(alpha_sect)))\n",
    "        page_counts_statement = (\"Page count = \" + str(page_counter[chr(alpha_sect)]))\n",
    "        shak_counts_statement = (\"Shakespeare citations = \" + str(shakespeares))\n",
    "        milton_counts_statement = (\"Milton citations = \" + str(miltons))\n",
    "        locke_counts_statement = (\"Locke citations = \" + str(lockes))\n",
    "        dryden_counts_statement = (\"Dryden citations = \" + str(drydens))\n",
    "        section_border = (\"- - - - - - - - - - - - -\")\n",
    "        \n",
    "        print(section_header, file=outfile_total_count)\n",
    "        print(page_counts_statement, file=outfile_total_count)\n",
    "        print(shak_counts_statement, file=outfile_total_count)\n",
    "        print(milton_counts_statement, file=outfile_total_count)\n",
    "        print(locke_counts_statement, file=outfile_total_count)\n",
    "        print(dryden_counts_statement, file=outfile_total_count)\n",
    "        print(section_border, file=outfile_total_count)\n",
    "\n",
    "        #redefine alpha_sect\n",
    "        if alpha_sect == 73:\n",
    "            alpha_sect = alpha_sect + 2\n",
    "        else:\n",
    "            alpha_sect = alpha_sect + 1\n",
    "\n",
    "    #adding to page count\n",
    "    elif 'div class=\"page\"' in line:\n",
    "        page_counter[chr(alpha_sect)] = page_counter[chr(alpha_sect)] + 1\n",
    "\n",
    "\n",
    "    #adding words and counts to dictionary\n",
    "    else:                                                   ## DICTIONARY COUNT ##\n",
    "        #identify whether any of the regex patterns are present in the string\n",
    "        shakespeares = len(shak.findall(line)) + shakespeares\n",
    "#        if (shak.findall(line)):                #write to the dictionary with key-value pair {shakespeare:string}\n",
    "#            alpha_dictionary[chr(alpha_sect)][line] = \"shakespeare\"\n",
    "        miltons = len(milton.findall(line)) + miltons\n",
    "#        if milton.findall(line):                #write to the dictionary with key-value pair {milton:string}\n",
    "        lockes = len(locke.findall(line)) + lockes\n",
    "#        if locke.findall(line):                 #write to the dictionary with key-value pair {locke:string}\n",
    "        drydens = len(dryden.findall(line)) + drydens\n",
    "#        if dryden.findall(line):                #write to the dictionary with key-value pair {dryden:string}\n",
    "            \n",
    "#outfile_csv.close()\n",
    "#csv_file.close()\n",
    "outfile_total_count.close()\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shake']\n",
      "{'shakespeare is cited here': 'shakespeare'}\n",
      "[]\n",
      "{'shakespeare is cited here': 'shakespeare', 'milton and locke are cited here': 'milton'}\n",
      "{'shakespeare is cited here': 'shakespeare', 'milton and locke are cited here': 'locke'}\n",
      "[]\n",
      "{'shakespeare is cited here': 'shakespeare', 'milton and locke are cited here': 'locke', 'dryden is cited here': 'dryden'}\n",
      "[]\n",
      "['shake', 'shake']\n",
      "{'shakespeare is cited here': 'shakespeare', 'milton and locke are cited here': 'locke', 'dryden is cited here': 'dryden', 'shakespeare shakespeare': 'shakespeare'}\n",
      "final dictionary is: {'shakespeare is cited here': 'shakespeare', 'milton and locke are cited here': 'locke', 'dryden is cited here': 'dryden', 'shakespeare shakespeare': 'shakespeare'}\n",
      "shakespeare citations = 3\n",
      "milton citations = 1\n",
      "locke citations = 1\n",
      "dryden citations = 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "shak = re.compile('shak[^i]')\n",
    "shakespeares = 0\n",
    "\n",
    "milton = re.compile('mil.')\n",
    "miltons = 0\n",
    "\n",
    "locke = re.compile('loc.')\n",
    "lockes = 0\n",
    "\n",
    "dryden = re.compile('dry[^i]')\n",
    "drydens = 0\n",
    "\n",
    "\n",
    "test_list = ['shakespeare is cited here', 'milton and locke are cited here', 'dryden is cited here', 'no one is cited here', 'shakespeare shakespeare']\n",
    "\n",
    "# dictionary of dictionaries:\n",
    "# key = alphabet section     #value = empty dictionary for word counts\n",
    "misc_dictionary = {\"dictionary1\":{}, \"dictionary2\":{}, \"dictionary3\":{}}\n",
    "\n",
    "for line in test_list:\n",
    "    #identify whether any of the regex patterns are present in the string\n",
    "    shakespeares = len(shak.findall(line)) + shakespeares\n",
    "    print(shak.findall(line))\n",
    "    if (shak.findall(line)):\n",
    "        #write to the dictionary with key-value pair {shakespeare:string}\n",
    "        misc_dictionary[\"dictionary1\"][line] = \"shakespeare\"\n",
    "        print(misc_dictionary[\"dictionary1\"])\n",
    "        \n",
    "    miltons = len(milton.findall(line)) + miltons\n",
    "    if milton.findall(line):\n",
    "        #write to the dictionary with key-value pair {milton:string}\n",
    "        misc_dictionary[\"dictionary1\"][line] = \"milton\"\n",
    "        print(misc_dictionary[\"dictionary1\"])\n",
    "        \n",
    "    lockes = len(locke.findall(line)) + lockes\n",
    "    if locke.findall(line):\n",
    "        #write to the dictionary with key-value pair {locke:string}\n",
    "        misc_dictionary[\"dictionary1\"][line] = \"locke\"\n",
    "        print(misc_dictionary[\"dictionary1\"])\n",
    "        \n",
    "    drydens = len(dryden.findall(line)) + drydens\n",
    "    if dryden.findall(line):\n",
    "        #write to the dictionary with key-value pair {dryden:string}\n",
    "        misc_dictionary[\"dictionary1\"][line] = \"dryden\"\n",
    "        print(misc_dictionary[\"dictionary1\"])\n",
    "        \n",
    "print(\"final dictionary is: \" + str(misc_dictionary[\"dictionary1\"]))\n",
    "\n",
    "print('shakespeare citations = ' + str(shakespeares))\n",
    "print('milton citations = ' + str(miltons))\n",
    "print('locke citations = ' + str(lockes))\n",
    "print('dryden citations = ' + str(drydens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div class=\"page\"\n"
     ]
    }
   ],
   "source": [
    "print('div class=\"page\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
